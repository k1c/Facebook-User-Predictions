{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "liwc_df = pd.read_csv(\"/Users/adityajoshi/facebook_analysis/Train/Text/liwc.csv\")\n",
    "nrc_df = pd.read_csv(\"/Users/adityajoshi/facebook_analysis/Train/Text/nrc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>WC</th>\n",
       "      <th>WPS</th>\n",
       "      <th>Sixltr</th>\n",
       "      <th>Dic</th>\n",
       "      <th>Numerals</th>\n",
       "      <th>funct</th>\n",
       "      <th>pronoun</th>\n",
       "      <th>ppron</th>\n",
       "      <th>i</th>\n",
       "      <th>...</th>\n",
       "      <th>Colon</th>\n",
       "      <th>SemiC</th>\n",
       "      <th>QMark</th>\n",
       "      <th>Exclam</th>\n",
       "      <th>Dash</th>\n",
       "      <th>Quote</th>\n",
       "      <th>Apostro</th>\n",
       "      <th>Parenth</th>\n",
       "      <th>OtherP</th>\n",
       "      <th>AllPct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1c1bb692d7765344d418c0247962e7f8</td>\n",
       "      <td>156</td>\n",
       "      <td>17.33</td>\n",
       "      <td>25.00</td>\n",
       "      <td>76.92</td>\n",
       "      <td>1.92</td>\n",
       "      <td>45.51</td>\n",
       "      <td>9.62</td>\n",
       "      <td>6.41</td>\n",
       "      <td>3.21</td>\n",
       "      <td>...</td>\n",
       "      <td>1.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.77</td>\n",
       "      <td>5.77</td>\n",
       "      <td>2.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.56</td>\n",
       "      <td>0.64</td>\n",
       "      <td>5.13</td>\n",
       "      <td>70.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2eba17f4ec950f23af8d31a1d1db4518</td>\n",
       "      <td>176</td>\n",
       "      <td>11.00</td>\n",
       "      <td>21.02</td>\n",
       "      <td>84.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>53.41</td>\n",
       "      <td>15.34</td>\n",
       "      <td>12.50</td>\n",
       "      <td>7.39</td>\n",
       "      <td>...</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.27</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.14</td>\n",
       "      <td>39.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4f3fc35de4f026bbe96d6aead80a011c</td>\n",
       "      <td>179</td>\n",
       "      <td>17.90</td>\n",
       "      <td>17.88</td>\n",
       "      <td>90.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>54.19</td>\n",
       "      <td>11.73</td>\n",
       "      <td>7.82</td>\n",
       "      <td>6.15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.68</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.59</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>41.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5b670721d060e5063273aefefd0e0731</td>\n",
       "      <td>179</td>\n",
       "      <td>179.00</td>\n",
       "      <td>20.67</td>\n",
       "      <td>77.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>51.40</td>\n",
       "      <td>12.29</td>\n",
       "      <td>9.50</td>\n",
       "      <td>4.47</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>34.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5ca01e48cdf661e932cfe58588360a7f</td>\n",
       "      <td>18</td>\n",
       "      <td>18.00</td>\n",
       "      <td>44.44</td>\n",
       "      <td>55.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>27.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>22.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3661.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.56</td>\n",
       "      <td>16.67</td>\n",
       "      <td>4111.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>7b561be60d859de59fec1929522643a8</td>\n",
       "      <td>164</td>\n",
       "      <td>18.22</td>\n",
       "      <td>23.78</td>\n",
       "      <td>73.17</td>\n",
       "      <td>0.61</td>\n",
       "      <td>40.85</td>\n",
       "      <td>12.80</td>\n",
       "      <td>10.37</td>\n",
       "      <td>9.76</td>\n",
       "      <td>...</td>\n",
       "      <td>8.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.61</td>\n",
       "      <td>13.41</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.52</td>\n",
       "      <td>1.83</td>\n",
       "      <td>64.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7eaa36752bccce478ab5ee651fcc4d68</td>\n",
       "      <td>125</td>\n",
       "      <td>20.83</td>\n",
       "      <td>29.60</td>\n",
       "      <td>71.20</td>\n",
       "      <td>1.60</td>\n",
       "      <td>38.40</td>\n",
       "      <td>13.60</td>\n",
       "      <td>11.20</td>\n",
       "      <td>7.20</td>\n",
       "      <td>...</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.20</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>33.60</td>\n",
       "      <td>97.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8bbb62b38592bcbf869e384f66d64383</td>\n",
       "      <td>155</td>\n",
       "      <td>10.33</td>\n",
       "      <td>20.65</td>\n",
       "      <td>41.29</td>\n",
       "      <td>1.29</td>\n",
       "      <td>25.16</td>\n",
       "      <td>5.81</td>\n",
       "      <td>4.52</td>\n",
       "      <td>3.87</td>\n",
       "      <td>...</td>\n",
       "      <td>0.65</td>\n",
       "      <td>2.58</td>\n",
       "      <td>4.52</td>\n",
       "      <td>3.23</td>\n",
       "      <td>1.94</td>\n",
       "      <td>1.94</td>\n",
       "      <td>1.94</td>\n",
       "      <td>0.97</td>\n",
       "      <td>19.35</td>\n",
       "      <td>81.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>23bb3332905ec10bf36b0e463a38bd5e</td>\n",
       "      <td>186</td>\n",
       "      <td>186.00</td>\n",
       "      <td>18.82</td>\n",
       "      <td>69.35</td>\n",
       "      <td>1.08</td>\n",
       "      <td>38.17</td>\n",
       "      <td>12.37</td>\n",
       "      <td>9.68</td>\n",
       "      <td>7.53</td>\n",
       "      <td>...</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1.08</td>\n",
       "      <td>5.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1.08</td>\n",
       "      <td>25.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>35e30200663adc2848fce13563497eed</td>\n",
       "      <td>168</td>\n",
       "      <td>21.00</td>\n",
       "      <td>20.24</td>\n",
       "      <td>74.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>48.81</td>\n",
       "      <td>14.29</td>\n",
       "      <td>9.52</td>\n",
       "      <td>4.17</td>\n",
       "      <td>...</td>\n",
       "      <td>2.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.52</td>\n",
       "      <td>24.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.98</td>\n",
       "      <td>66.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             userId   WC     WPS  Sixltr    Dic  Numerals  \\\n",
       "0  1c1bb692d7765344d418c0247962e7f8  156   17.33   25.00  76.92      1.92   \n",
       "1  2eba17f4ec950f23af8d31a1d1db4518  176   11.00   21.02  84.66      0.00   \n",
       "2  4f3fc35de4f026bbe96d6aead80a011c  179   17.90   17.88  90.50      0.00   \n",
       "3  5b670721d060e5063273aefefd0e0731  179  179.00   20.67  77.09      0.00   \n",
       "4  5ca01e48cdf661e932cfe58588360a7f   18   18.00   44.44  55.56      0.00   \n",
       "5  7b561be60d859de59fec1929522643a8  164   18.22   23.78  73.17      0.61   \n",
       "6  7eaa36752bccce478ab5ee651fcc4d68  125   20.83   29.60  71.20      1.60   \n",
       "7  8bbb62b38592bcbf869e384f66d64383  155   10.33   20.65  41.29      1.29   \n",
       "8  23bb3332905ec10bf36b0e463a38bd5e  186  186.00   18.82  69.35      1.08   \n",
       "9  35e30200663adc2848fce13563497eed  168   21.00   20.24  74.40      0.00   \n",
       "\n",
       "   funct  pronoun  ppron     i  ...  Colon  SemiC    QMark  Exclam  Dash  \\\n",
       "0  45.51     9.62   6.41  3.21  ...   1.92   0.00     5.77    5.77  2.56   \n",
       "1  53.41    15.34  12.50  7.39  ...   0.57   0.00     0.00   13.07  0.00   \n",
       "2  54.19    11.73   7.82  6.15  ...   0.00   0.56     0.56    1.68  1.12   \n",
       "3  51.40    12.29   9.50  4.47  ...   0.00   0.00     1.68    0.00  1.12   \n",
       "4  27.78     0.00   0.00  0.00  ...  22.22   0.00  3661.11    0.00  0.00   \n",
       "5  40.85    12.80  10.37  9.76  ...   8.54   0.00     0.61   13.41  0.61   \n",
       "6  38.40    13.60  11.20  7.20  ...   2.40   0.00     0.00   15.20  1.60   \n",
       "7  25.16     5.81   4.52  3.87  ...   0.65   2.58     4.52    3.23  1.94   \n",
       "8  38.17    12.37   9.68  7.53  ...   0.54   0.54     1.08    5.38  0.00   \n",
       "9  48.81    14.29   9.52  4.17  ...   2.38   0.00     9.52   24.40  0.00   \n",
       "\n",
       "   Quote  Apostro  Parenth  OtherP   AllPct  \n",
       "0   0.00     2.56     0.64    5.13    70.51  \n",
       "1   0.00     2.27     0.28    1.14    39.77  \n",
       "2   0.00     5.59     0.28    0.00    41.90  \n",
       "3   0.00     2.23     0.00    0.00    34.64  \n",
       "4  11.11     0.00     5.56   16.67  4111.11  \n",
       "5   0.00     1.22     1.52    1.83    64.63  \n",
       "6   0.00    24.00     0.80   33.60    97.60  \n",
       "7   1.94     1.94     0.97   19.35    81.94  \n",
       "8   0.00     0.00     0.54    1.08    25.27  \n",
       "9   0.00     0.60     0.30    2.98    66.07  \n",
       "\n",
       "[10 rows x 82 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liwc_df.head(n=10)\n",
    "# print(liwc_df.columns)\n",
    "# print(liwc_df.shape)\n",
    "# print(liwc_df.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0000e06e07496624211632e8e264126c</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>000235a2ba2f48231b7d24e1f08d7878</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.218750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>000c4b6e2468f7d528876fd1a6dffd4c</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.127273</td>\n",
       "      <td>0.163636</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.127273</td>\n",
       "      <td>0.163636</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>001187432d2a247562082cd0000dec40</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.084746</td>\n",
       "      <td>0.186441</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>0.084746</td>\n",
       "      <td>0.254237</td>\n",
       "      <td>0.101695</td>\n",
       "      <td>0.101695</td>\n",
       "      <td>0.152542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>001494c3b74f124a2e3435fff17f376b</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.134615</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.057692</td>\n",
       "      <td>0.346154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0016684d01925c6e96ba9895801207c8</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>001d4fa530e67f4fa73374472a59ef5d</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.290323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>00200961a099690696e2854d1ac7f186</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0.108108</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>0.189189</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>0.162162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0028c7db14b7a987bac0f3163239eaa9</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.255814</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.069767</td>\n",
       "      <td>0.232558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>002efabe296f426d60b815c26517749a</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.072727</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.109091</td>\n",
       "      <td>0.163636</td>\n",
       "      <td>0.236364</td>\n",
       "      <td>0.109091</td>\n",
       "      <td>0.127273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             userId  positive  negative     anger  \\\n",
       "0  0000e06e07496624211632e8e264126c  0.578947  0.421053  0.107143   \n",
       "1  000235a2ba2f48231b7d24e1f08d7878  0.450000  0.550000  0.156250   \n",
       "2  000c4b6e2468f7d528876fd1a6dffd4c  0.617647  0.382353  0.127273   \n",
       "3  001187432d2a247562082cd0000dec40  0.730769  0.269231  0.084746   \n",
       "4  001494c3b74f124a2e3435fff17f376b  0.875000  0.125000  0.019231   \n",
       "5  0016684d01925c6e96ba9895801207c8  0.857143  0.142857  0.055556   \n",
       "6  001d4fa530e67f4fa73374472a59ef5d  0.818182  0.181818  0.032258   \n",
       "7  00200961a099690696e2854d1ac7f186  0.520000  0.480000  0.135135   \n",
       "8  0028c7db14b7a987bac0f3163239eaa9  0.920000  0.080000  0.023256   \n",
       "9  002efabe296f426d60b815c26517749a  0.375000  0.625000  0.072727   \n",
       "\n",
       "   anticipation   disgust      fear       joy   sadness  surprise     trust  \n",
       "0      0.107143  0.071429  0.214286  0.142857  0.178571  0.035714  0.142857  \n",
       "1      0.125000  0.125000  0.093750  0.187500  0.093750  0.000000  0.218750  \n",
       "2      0.163636  0.090909  0.127273  0.163636  0.090909  0.036364  0.200000  \n",
       "3      0.186441  0.033898  0.084746  0.254237  0.101695  0.101695  0.152542  \n",
       "4      0.134615  0.019231  0.019231  0.384615  0.019231  0.057692  0.346154  \n",
       "5      0.166667  0.055556  0.111111  0.194444  0.111111  0.083333  0.222222  \n",
       "6      0.193548  0.000000  0.064516  0.258065  0.032258  0.129032  0.290323  \n",
       "7      0.108108  0.081081  0.162162  0.081081  0.189189  0.081081  0.162162  \n",
       "8      0.255814  0.023256  0.046512  0.325581  0.023256  0.069767  0.232558  \n",
       "9      0.090909  0.090909  0.109091  0.163636  0.236364  0.109091  0.127273  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nrc_df.head(n=10)\n",
    "# print(nrc_df.columns)\n",
    "# print(nrc_df.shape)\n",
    "# print(nrc_df.isnull())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>WC</th>\n",
       "      <th>WPS</th>\n",
       "      <th>Sixltr</th>\n",
       "      <th>Dic</th>\n",
       "      <th>Numerals</th>\n",
       "      <th>funct</th>\n",
       "      <th>pronoun</th>\n",
       "      <th>ppron</th>\n",
       "      <th>i</th>\n",
       "      <th>...</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>anger_y</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1c1bb692d7765344d418c0247962e7f8</td>\n",
       "      <td>156</td>\n",
       "      <td>17.33</td>\n",
       "      <td>25.00</td>\n",
       "      <td>76.92</td>\n",
       "      <td>1.92</td>\n",
       "      <td>45.51</td>\n",
       "      <td>9.62</td>\n",
       "      <td>6.41</td>\n",
       "      <td>3.21</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2eba17f4ec950f23af8d31a1d1db4518</td>\n",
       "      <td>176</td>\n",
       "      <td>11.00</td>\n",
       "      <td>21.02</td>\n",
       "      <td>84.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>53.41</td>\n",
       "      <td>15.34</td>\n",
       "      <td>12.50</td>\n",
       "      <td>7.39</td>\n",
       "      <td>...</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>0.258065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4f3fc35de4f026bbe96d6aead80a011c</td>\n",
       "      <td>179</td>\n",
       "      <td>17.90</td>\n",
       "      <td>17.88</td>\n",
       "      <td>90.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>54.19</td>\n",
       "      <td>11.73</td>\n",
       "      <td>7.82</td>\n",
       "      <td>6.15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.172414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5b670721d060e5063273aefefd0e0731</td>\n",
       "      <td>179</td>\n",
       "      <td>179.00</td>\n",
       "      <td>20.67</td>\n",
       "      <td>77.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>51.40</td>\n",
       "      <td>12.29</td>\n",
       "      <td>9.50</td>\n",
       "      <td>4.47</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.228070</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.280702</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.280702</td>\n",
       "      <td>0.070175</td>\n",
       "      <td>0.035088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5ca01e48cdf661e932cfe58588360a7f</td>\n",
       "      <td>18</td>\n",
       "      <td>18.00</td>\n",
       "      <td>44.44</td>\n",
       "      <td>55.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>27.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>7b561be60d859de59fec1929522643a8</td>\n",
       "      <td>164</td>\n",
       "      <td>18.22</td>\n",
       "      <td>23.78</td>\n",
       "      <td>73.17</td>\n",
       "      <td>0.61</td>\n",
       "      <td>40.85</td>\n",
       "      <td>12.80</td>\n",
       "      <td>10.37</td>\n",
       "      <td>9.76</td>\n",
       "      <td>...</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7eaa36752bccce478ab5ee651fcc4d68</td>\n",
       "      <td>125</td>\n",
       "      <td>20.83</td>\n",
       "      <td>29.60</td>\n",
       "      <td>71.20</td>\n",
       "      <td>1.60</td>\n",
       "      <td>38.40</td>\n",
       "      <td>13.60</td>\n",
       "      <td>11.20</td>\n",
       "      <td>7.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8bbb62b38592bcbf869e384f66d64383</td>\n",
       "      <td>155</td>\n",
       "      <td>10.33</td>\n",
       "      <td>20.65</td>\n",
       "      <td>41.29</td>\n",
       "      <td>1.29</td>\n",
       "      <td>25.16</td>\n",
       "      <td>5.81</td>\n",
       "      <td>4.52</td>\n",
       "      <td>3.87</td>\n",
       "      <td>...</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>23bb3332905ec10bf36b0e463a38bd5e</td>\n",
       "      <td>186</td>\n",
       "      <td>186.00</td>\n",
       "      <td>18.82</td>\n",
       "      <td>69.35</td>\n",
       "      <td>1.08</td>\n",
       "      <td>38.17</td>\n",
       "      <td>12.37</td>\n",
       "      <td>9.68</td>\n",
       "      <td>7.53</td>\n",
       "      <td>...</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.127273</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.145455</td>\n",
       "      <td>0.109091</td>\n",
       "      <td>0.163636</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.127273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>35e30200663adc2848fce13563497eed</td>\n",
       "      <td>168</td>\n",
       "      <td>21.00</td>\n",
       "      <td>20.24</td>\n",
       "      <td>74.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>48.81</td>\n",
       "      <td>14.29</td>\n",
       "      <td>9.52</td>\n",
       "      <td>4.17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             userId   WC     WPS  Sixltr    Dic  Numerals  \\\n",
       "0  1c1bb692d7765344d418c0247962e7f8  156   17.33   25.00  76.92      1.92   \n",
       "1  2eba17f4ec950f23af8d31a1d1db4518  176   11.00   21.02  84.66      0.00   \n",
       "2  4f3fc35de4f026bbe96d6aead80a011c  179   17.90   17.88  90.50      0.00   \n",
       "3  5b670721d060e5063273aefefd0e0731  179  179.00   20.67  77.09      0.00   \n",
       "4  5ca01e48cdf661e932cfe58588360a7f   18   18.00   44.44  55.56      0.00   \n",
       "5  7b561be60d859de59fec1929522643a8  164   18.22   23.78  73.17      0.61   \n",
       "6  7eaa36752bccce478ab5ee651fcc4d68  125   20.83   29.60  71.20      1.60   \n",
       "7  8bbb62b38592bcbf869e384f66d64383  155   10.33   20.65  41.29      1.29   \n",
       "8  23bb3332905ec10bf36b0e463a38bd5e  186  186.00   18.82  69.35      1.08   \n",
       "9  35e30200663adc2848fce13563497eed  168   21.00   20.24  74.40      0.00   \n",
       "\n",
       "   funct  pronoun  ppron     i  ...  positive  negative   anger_y  \\\n",
       "0  45.51     9.62   6.41  3.21  ...  0.750000  0.250000  0.200000   \n",
       "1  53.41    15.34  12.50  7.39  ...  0.684211  0.315789  0.096774   \n",
       "2  54.19    11.73   7.82  6.15  ...  0.631579  0.368421  0.103448   \n",
       "3  51.40    12.29   9.50  4.47  ...  0.206897  0.793103  0.228070   \n",
       "4  27.78     0.00   0.00  0.00  ...  1.000000  0.000000  0.000000   \n",
       "5  40.85    12.80  10.37  9.76  ...  0.380952  0.619048  0.285714   \n",
       "6  38.40    13.60  11.20  7.20  ...  0.636364  0.363636  0.115385   \n",
       "7  25.16     5.81   4.52  3.87  ...  0.473684  0.526316  0.117647   \n",
       "8  38.17    12.37   9.68  7.53  ...  0.354839  0.645161  0.200000   \n",
       "9  48.81    14.29   9.52  4.17  ...  0.666667  0.333333  0.121212   \n",
       "\n",
       "   anticipation   disgust      fear       joy   sadness  surprise     trust  \n",
       "0      0.150000  0.150000  0.100000  0.050000  0.150000  0.000000  0.200000  \n",
       "1      0.193548  0.000000  0.064516  0.225806  0.064516  0.096774  0.258065  \n",
       "2      0.172414  0.034483  0.137931  0.137931  0.172414  0.068966  0.172414  \n",
       "3      0.035088  0.052632  0.280702  0.017544  0.280702  0.070175  0.035088  \n",
       "4      0.444444  0.000000  0.000000  0.333333  0.000000  0.000000  0.222222  \n",
       "5      0.190476  0.142857  0.095238  0.095238  0.095238  0.047619  0.047619  \n",
       "6      0.153846  0.038462  0.115385  0.192308  0.115385  0.115385  0.153846  \n",
       "7      0.117647  0.147059  0.176471  0.088235  0.205882  0.029412  0.117647  \n",
       "8      0.127273  0.090909  0.145455  0.109091  0.163636  0.036364  0.127273  \n",
       "9      0.121212  0.121212  0.121212  0.181818  0.121212  0.030303  0.181818  \n",
       "\n",
       "[10 rows x 92 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liwc_nrc_features = liwc_df.merge(nrc_df, how='inner', left_on='userId', right_on='userId', validate='one_to_one')\n",
    "# print(liwc_nrc_features.columns)\n",
    "# print(liwc_nrc_features.shape)\n",
    "# print(liwc_nrc_features.isnull())\n",
    "liwc_nrc_features.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WC</th>\n",
       "      <th>WPS</th>\n",
       "      <th>Sixltr</th>\n",
       "      <th>Dic</th>\n",
       "      <th>Numerals</th>\n",
       "      <th>funct</th>\n",
       "      <th>pronoun</th>\n",
       "      <th>ppron</th>\n",
       "      <th>i</th>\n",
       "      <th>we</th>\n",
       "      <th>...</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>anger_y</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>17.33</td>\n",
       "      <td>25.00</td>\n",
       "      <td>76.92</td>\n",
       "      <td>1.92</td>\n",
       "      <td>45.51</td>\n",
       "      <td>9.62</td>\n",
       "      <td>6.41</td>\n",
       "      <td>3.21</td>\n",
       "      <td>1.28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>176</td>\n",
       "      <td>11.00</td>\n",
       "      <td>21.02</td>\n",
       "      <td>84.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>53.41</td>\n",
       "      <td>15.34</td>\n",
       "      <td>12.50</td>\n",
       "      <td>7.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>0.258065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>179</td>\n",
       "      <td>17.90</td>\n",
       "      <td>17.88</td>\n",
       "      <td>90.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>54.19</td>\n",
       "      <td>11.73</td>\n",
       "      <td>7.82</td>\n",
       "      <td>6.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.172414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>179</td>\n",
       "      <td>179.00</td>\n",
       "      <td>20.67</td>\n",
       "      <td>77.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>51.40</td>\n",
       "      <td>12.29</td>\n",
       "      <td>9.50</td>\n",
       "      <td>4.47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.228070</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.280702</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.280702</td>\n",
       "      <td>0.070175</td>\n",
       "      <td>0.035088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>18.00</td>\n",
       "      <td>44.44</td>\n",
       "      <td>55.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>27.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>164</td>\n",
       "      <td>18.22</td>\n",
       "      <td>23.78</td>\n",
       "      <td>73.17</td>\n",
       "      <td>0.61</td>\n",
       "      <td>40.85</td>\n",
       "      <td>12.80</td>\n",
       "      <td>10.37</td>\n",
       "      <td>9.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>125</td>\n",
       "      <td>20.83</td>\n",
       "      <td>29.60</td>\n",
       "      <td>71.20</td>\n",
       "      <td>1.60</td>\n",
       "      <td>38.40</td>\n",
       "      <td>13.60</td>\n",
       "      <td>11.20</td>\n",
       "      <td>7.20</td>\n",
       "      <td>3.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>155</td>\n",
       "      <td>10.33</td>\n",
       "      <td>20.65</td>\n",
       "      <td>41.29</td>\n",
       "      <td>1.29</td>\n",
       "      <td>25.16</td>\n",
       "      <td>5.81</td>\n",
       "      <td>4.52</td>\n",
       "      <td>3.87</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>186</td>\n",
       "      <td>186.00</td>\n",
       "      <td>18.82</td>\n",
       "      <td>69.35</td>\n",
       "      <td>1.08</td>\n",
       "      <td>38.17</td>\n",
       "      <td>12.37</td>\n",
       "      <td>9.68</td>\n",
       "      <td>7.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.127273</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.145455</td>\n",
       "      <td>0.109091</td>\n",
       "      <td>0.163636</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.127273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>168</td>\n",
       "      <td>21.00</td>\n",
       "      <td>20.24</td>\n",
       "      <td>74.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>48.81</td>\n",
       "      <td>14.29</td>\n",
       "      <td>9.52</td>\n",
       "      <td>4.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    WC     WPS  Sixltr    Dic  Numerals  funct  pronoun  ppron     i    we  \\\n",
       "0  156   17.33   25.00  76.92      1.92  45.51     9.62   6.41  3.21  1.28   \n",
       "1  176   11.00   21.02  84.66      0.00  53.41    15.34  12.50  7.39  0.00   \n",
       "2  179   17.90   17.88  90.50      0.00  54.19    11.73   7.82  6.15  0.00   \n",
       "3  179  179.00   20.67  77.09      0.00  51.40    12.29   9.50  4.47  0.00   \n",
       "4   18   18.00   44.44  55.56      0.00  27.78     0.00   0.00  0.00  0.00   \n",
       "5  164   18.22   23.78  73.17      0.61  40.85    12.80  10.37  9.76  0.00   \n",
       "6  125   20.83   29.60  71.20      1.60  38.40    13.60  11.20  7.20  3.20   \n",
       "7  155   10.33   20.65  41.29      1.29  25.16     5.81   4.52  3.87  0.00   \n",
       "8  186  186.00   18.82  69.35      1.08  38.17    12.37   9.68  7.53  0.00   \n",
       "9  168   21.00   20.24  74.40      0.00  48.81    14.29   9.52  4.17  0.00   \n",
       "\n",
       "   ...  positive  negative   anger_y  anticipation   disgust      fear  \\\n",
       "0  ...  0.750000  0.250000  0.200000      0.150000  0.150000  0.100000   \n",
       "1  ...  0.684211  0.315789  0.096774      0.193548  0.000000  0.064516   \n",
       "2  ...  0.631579  0.368421  0.103448      0.172414  0.034483  0.137931   \n",
       "3  ...  0.206897  0.793103  0.228070      0.035088  0.052632  0.280702   \n",
       "4  ...  1.000000  0.000000  0.000000      0.444444  0.000000  0.000000   \n",
       "5  ...  0.380952  0.619048  0.285714      0.190476  0.142857  0.095238   \n",
       "6  ...  0.636364  0.363636  0.115385      0.153846  0.038462  0.115385   \n",
       "7  ...  0.473684  0.526316  0.117647      0.117647  0.147059  0.176471   \n",
       "8  ...  0.354839  0.645161  0.200000      0.127273  0.090909  0.145455   \n",
       "9  ...  0.666667  0.333333  0.121212      0.121212  0.121212  0.121212   \n",
       "\n",
       "        joy   sadness  surprise     trust  \n",
       "0  0.050000  0.150000  0.000000  0.200000  \n",
       "1  0.225806  0.064516  0.096774  0.258065  \n",
       "2  0.137931  0.172414  0.068966  0.172414  \n",
       "3  0.017544  0.280702  0.070175  0.035088  \n",
       "4  0.333333  0.000000  0.000000  0.222222  \n",
       "5  0.095238  0.095238  0.047619  0.047619  \n",
       "6  0.192308  0.115385  0.115385  0.153846  \n",
       "7  0.088235  0.205882  0.029412  0.117647  \n",
       "8  0.109091  0.163636  0.036364  0.127273  \n",
       "9  0.181818  0.121212  0.030303  0.181818  \n",
       "\n",
       "[10 rows x 91 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liwc_nrc_features = liwc_nrc_features.drop([\"userId\"], axis=1)\n",
    "# print(liwc_nrc_features.columns)\n",
    "# print(liwc_nrc_features.shape)\n",
    "# print(liwc_nrc_features.isnull())\n",
    "liwc_nrc_features.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "#from src.data.user_features import UserFeatures\n",
    "from src.data.user_labels import UserLabels\n",
    "from src.estimators.base.age_estimator import AgeEstimator\n",
    "\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get age targets for each user in liwc and nrc\n",
    "def extract_targets(df: pd.DataFrame, labels: List[UserLabels]) -> np.array:\n",
    "    user_id_to_label = {label.user_id: label.age for label in labels}\n",
    "    targets = list()\n",
    "    for _, row in df.iterrows():\n",
    "        targets.append(user_id_to_label[row[\"userId\"]])\n",
    "    return targets\n",
    "\n",
    "# get the features related to a user in liwc and nrc\n",
    "def extract_features(df: pd.DataFrame, user_id: str) -> Optional[pd.DataFrame]:\n",
    "    rows = df[df[\"userId\"] == user_id]\n",
    "    if len(rows) == 0:\n",
    "        return None\n",
    "    elif len(rows) == 1:\n",
    "        return rows.to_frame().T if isinstance(rows, pd.Series) else rows\n",
    "    else:\n",
    "        row = rows.iloc[0]\n",
    "        return row.to_frame().T if isinstance(row, pd.Series) else row\n",
    "\n",
    "def merge_features(liwc_df: pd.DataFrame, nrc_df: pd.DataFrame):\n",
    "    # remove duplicate userId and keep the first one (didn't find any duplicated for both features, but doing this in case)\n",
    "    liwc_df = liwc_df.drop_duplicates(\n",
    "        subset=[\"userId\"],\n",
    "        keep=\"first\"\n",
    "    )\n",
    "    nrc_df = nrc_df.drop_duplicates(\n",
    "        subset=[\"userId\"],\n",
    "        keep=\"first\"\n",
    "    )\n",
    "\n",
    "    liwc_nrc_df = liwc_df.merge(nrc_df, how='inner', left_on='userId', right_on='userId',validate='one_to_one')\n",
    "\n",
    "    return liwc_nrc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.readers import read_train_data\n",
    "features, labels = read_train_data(data_path=\"/Users/adityajoshi/facebook_analysis/Train/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "liwc_nrc_df = merge_features(liwc_df, nrc_df)\n",
    "liwc_nrc_features = liwc_nrc_df.drop([\"userId\"], axis=1)\n",
    "\n",
    "liwc_nrc_targets = extract_targets(liwc_nrc_df, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = namedtuple(\"Data\", ['X', 'y'])\n",
    "NAVY = \"#001f3f\"\n",
    "\n",
    "\n",
    "def experiment(estimator, preprocessed_train, hyper_parameter_name, hyper_parameter_values, x_axis_label):\n",
    "    train_scores, valid_scores = validation_curve(estimator,\n",
    "                                                  preprocessed_train.X,\n",
    "                                                  preprocessed_train.y,\n",
    "                                                  hyper_parameter_name,\n",
    "                                                  hyper_parameter_values,\n",
    "                                                  cv=4,\n",
    "                                                  verbose=3,\n",
    "                                                  n_jobs=3,\n",
    "                                                  scoring=\"accuracy\")\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    valid_scores_mean = np.mean(valid_scores, axis=1)\n",
    "    valid_scores_std = np.std(valid_scores, axis=1)\n",
    "    plt.title(\"Validation Curve with xgboost for Age Classification\")\n",
    "    plt.xlabel(x_axis_label)\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    lw = 2\n",
    "\n",
    "    plt.plot(hyper_parameter_values, train_scores_mean, label=\"Training Accuracy\",\n",
    "                 color=\"darkorange\", lw=lw)\n",
    "    plt.fill_between(hyper_parameter_values, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                     color=\"darkorange\", lw=lw)\n",
    "    plt.plot(hyper_parameter_values, valid_scores_mean, label=\"Cross-Validation Accuracy\",\n",
    "                 color=NAVY, lw=lw)\n",
    "    plt.fill_between(hyper_parameter_values, valid_scores_mean - valid_scores_std,\n",
    "                     valid_scores_mean + valid_scores_std, alpha=0.2,\n",
    "                     color=NAVY, lw=lw)\n",
    "    print(\"Training Accuracy:\", train_scores)\n",
    "    print(\"Valid Accuracy:\", valid_scores)\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = Data(X=liwc_nrc_features.values, y=liwc_nrc_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   7 out of  20 | elapsed:   26.4s remaining:   49.1s\n",
      "[Parallel(n_jobs=3)]: Done  14 out of  20 | elapsed:   26.4s remaining:   11.3s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-bee5097b5b95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m            \u001b[0;34m\"n_estimators\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m            \u001b[0;34m[\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m800\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m            \"Number of Estimators\")\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-9ff7cccc906a>\u001b[0m in \u001b[0;36mexperiment\u001b[0;34m(estimator, preprocessed_train, hyper_parameter_name, hyper_parameter_values, x_axis_label)\u001b[0m\n\u001b[1;32m     12\u001b[0m                                                   \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                                                   \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                                                   scoring=\"accuracy\")\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mtrain_scores_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mtrain_scores_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mvalidation_curve\u001b[0;34m(estimator, X, y, param_name, param_range, groups, cv, scoring, n_jobs, pre_dispatch, verbose, error_score)\u001b[0m\n\u001b[1;32m   1496\u001b[0m         error_score=error_score)\n\u001b[1;32m   1497\u001b[0m         \u001b[0;31m# NOTE do not change order of iteration to allow one time cv splitters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1498\u001b[0;31m         for train, test in cv.split(X, y, groups) for v in param_range)\n\u001b[0m\u001b[1;32m   1499\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[0mn_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Experiment 1: CV on Number of Boosting Stages.\n",
    "#!pip3 install xgboost\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "#from xgboost import XGBRegressor\n",
    "experiment(GradientBoostingClassifier(max_depth=3, learning_rate=0.1), \n",
    "           training_data,\n",
    "           \"n_estimators\",\n",
    "           [200,300,400,500,800],\n",
    "           \"Number of Estimators\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(GradientBoostingClassifier(n_estimators=500),\n",
    "           training_data,\n",
    "           \"max_depth\",\n",
    "           [1,2,3,5,7],\n",
    "           \"Max Depth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(GradientBoostingClassifier(n_estimators=500, max_depth=1.5),\n",
    "           training_data,\n",
    "           \"learning_rate\",\n",
    "           [0.01, 0.1,0.2,0.5,1.0],\n",
    "           \"Learning Rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn_evaluation import plot\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(liwc_nrc_features.values, np.array(liwc_nrc_targets), test_size=0.30)\n",
    "clf = GradientBoostingClassifier(n_estimators=500)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a26c9ef90>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plot.confusion_matrix(y_test, y_pred)\n",
    "plt.subplot(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n       25-34       0.37      0.21      0.26       760\\n       35-49       0.33      0.19      0.24       303\\n       50-xx       0.26      0.06      0.10       124\\n       xx-24       0.67      0.89      0.77      1663\\n\\n    accuracy                           0.60      2850\\n   macro avg       0.41      0.34      0.34      2850\\nweighted avg       0.53      0.60      0.55      2850\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
